\documentclass[12pt, twoside, openany]{report}
\usepackage[dvips]{rotating}
\usepackage[utf8]{inputenc}
\usepackage{t1enc}
\usepackage{a4wide}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage[MeX]{polski}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{left=25mm,right=25mm,%
bindingoffset=10mm, top=25mm, bottom=25mm}
\usepackage{amssymb, latexsym}
\usepackage{amsthm}
\usepackage{palatino}
\usepackage{array}
\usepackage{pstricks}
\usepackage{textcomp}
\usepackage{hyperref}
%paginy
\usepackage{fancyhdr}
\pagestyle{fancy}
% zmiana liter w~.ywej paginie na ma.e
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\fancyhf{} % usu. bie..ce ustawienia pagin
\fancyhead[LE,RO]{\small\bfseries\thepage}
\fancyhead[LO]{\small\bfseries\rightmark}
\fancyhead[RE]{\small\bfseries\leftmark}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0pt}
\addtolength{\headheight}{0.5pt} % pionowy odst.p na kresk.
\fancypagestyle{plain}{%
\fancyhead{} % usu. p. górne na stronach pozbawionych
% numeracji (plain)
\renewcommand{\headrulewidth}{0pt} % pozioma kreska
}
%paginy koniec
\theoremstyle{plain}
\newtheorem{tw}{Twierdzenie}[section]
\newtheorem{uw}{Uwaga}[section]
\newtheorem{defi}{Definicja}[section]
\newtheorem{alg}{Algorytm}[chapter]
\newtheorem{przyp}{Przypadek}[section]
\newtheorem{prz}{Przykład}[section]
\newtheorem{lem}[tw]{Lemat}
\newtheorem{stw}[tw]{Stwierdzenie}
\newtheorem{wn}[tw]{Wniosek}
\newtheorem{cw}{Ćwiczenie}[section]
\linespread{1.5}
\author{Natalia Potocka}
\title{Słowa - statystyki}
\begin{document}
\maketitle
\hyphenation{Syl-ves-tra}
\hyphenation{Syl-ves-ter-a}
\newpage
<<echo=FALSE>>=
opts_chunk$set(echo=FALSE, cache=TRUE, eval=TRUE, message=FALSE, comment="")
options(scipen = 1, digits = 2)
library(stringi)
library(xtable)
library(ggplot2)
@

<<ws>>=
word_stat <- 
  readRDS("../Data/RObjects/words_cnt.rds")
n_words <- nrow(word_stat)
n_once <- sum(word_stat$word_cnt==1)/n_words*100
@

<<ws_all>>=
word_stat_all <- 
  readRDS("../Data/RObjects/words_cnt_all.rds")
n_words_all <- nrow(word_stat_all)
n_once_all <- sum(word_stat_all$word_cnt==1)/n_words_all*100
@

W polskiej Wikipedii znaleziono \Sexpr{n_words} unikalnych słów. \Sexpr{n_once}\% z nich występuje dokładnie w jednym tekście, natomiast \Sexpr{n_once_all}\% występuje tylko raz. Dobrze obrazuje to poniższy histogram.

<<hist, dependson='ws'>>=
ggplot(word_stat, aes(x=word_cnt), main="Liczba występowania słów w artykułach") + 
  geom_histogram(fill="white", colour="black")
@

Słowa występujące tylko w jednym tekście to zazwyczaj liczby oraz słowa w obcych językach, przykładowo:

<<once, dependson='ws'>>=
set.seed(6785)
cat(sample(word_stat$word[word_stat$word_cnt==1], 10), sep = ", ")
@

choć czasem są to słowa będące odmianą słów bardziej częściej występujących, np. słowo \emph{uchybiają} jest odmianą czasownika \emph{uchybiać}. Należy wziąć pod uwagę takie słowa, gdyż mogą one polepszyć jakość dopasowania tekstów pod względem tematycznym.

% Po usunięciu słów występujących w jednym, dwóch lub trzech tekstach otrzymujemy następujące statystyki:
%
% <<stat_3, dependson='ws'>>=
% cnt <- 3
% stat_cnt <- which(word_stat$word_cnt>cnt)
% print(summary(word_stat$word_cnt[stat_cnt]))
% n_stat_3 <- length(stat_cnt)/n_words*100
% @
%
%
% Słowa, które występują przynajmniej w czterech stanowią zaledwie \Sexpr{n_stat_3}\% wszystkich słów.

Słowa występujące w największej liczbie tekstów to:\\

<<top10, dependson=c('ws', 'ws_all'), results='asis'>>=
top10 <- head(word_stat, 10)
top10 <- cbind(top10, top10[,1])[,-1]
top10_all <- numeric(10)
for(i in 1:length(top10[,1])){
top10_all[i] <- word_stat_all$word_cnt_all[which(word_stat_all$word==top10[i,1])]
}
top10 <- cbind(top10, top10_all)
names(top10) <- c("Słowo", "Liczba artykułów", "Liczba wystąpień słowa")
tab <- xtable(top10, caption="Lista dziesięciu najczęściej występujących słów.")
digits(tab)[c(3,4)] <- 0
print(tab, floating=FALSE, latex.environments='center')
@


%%%%%%%%%%%%%%%%% TO DO %%%%%%%%%%%%%%%%%%%%%%
%%%% wgrac (slowo, licznosc slowa ogolem) %%%%
W większości przypadków są to słowa nie istotne w kontekście analizy tematycznej tekstu. Podobnych słów jest więcej. Ich pełna lista zostaje przedstawiona poniżej:
<<stopwords>>=
stopwords <- as.vector(read.table("../Data//RObjects//stopwords2.txt", sep="")[,1])
print(stopwords)
@

<<rm_stp, , dependson=c('ws', 'stopwords')>>=
words <- data.frame(word=setdiff(word_stat$word, stopwords))
word_no_stp <- merge(word_stat, words)
n_no_stp <- nrow(words)
@


Po usunięciu wyżej wymienionych słów pozostaje \Sexpr{n_no_stp} unikalnych słów do analizy.

<<hist_stp, dependson='rm_stp'>>=
ggplot(word_no_stp, aes(x=word)) +
geom_histogram(fill="white", colour="black")
print(summary(word_no_stp$word_cnt))
@


\end{document}