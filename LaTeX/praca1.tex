\documentclass{praca1}
\usepackage[utf8]{inputenc}
%%------------------------------------------------------------------------------%

%------------------------------------------------------------------------------%

%\usepackage[dvips]{graphicx,color,rotating}
%\usepackage[utf8]{inputenc}
%\usepackage{t1enc}
%\usepackage{a4wide}
%\usepackage{amsfonts}
%\usepackage{amsmath}
%%\usepackage{enumitem}
%\usepackage{enumerate}
%\usepackage{verbatim}
%\usepackage[MeX]{polski}
%\usepackage[T1]{fontenc}
%\usepackage{geometry}
%\geometry{left=25mm,right=25mm,%
%bindingoffset=10mm, top=25mm, bottom=25mm}
%\usepackage{amssymb, latexsym}
%\usepackage{amsthm}
%\usepackage{palatino}
%\usepackage{array}
%\usepackage{pstricks}
%\usepackage{textcomp}
%\usepackage{hyperref}
%%paginy
%\usepackage{fancyhdr}





\author{Natalia Potocka}
\title{Automatyczna kategoryzacja tematyczna tekstów przy użyciu metryk w przestrzeni ciągów znaków}
\supervisor{dr Marek Gągolewski}
\type{magisters}
\discipline{matematyka}
\monthyear{grudzień 2015}
\date{\today}
\album{237476}

\begin{document}
%\maketitle
%\tableofcontents

%-----------Początek części zasadniczej-----------

%
%\chapter*{Wstęp}
%\addcontentsline{toc}{chapter}{Wstęp}
%COŚ tu będzie.

\chapter{Metryki na przestrzeni ciągów znaków}\label{metryki-na-przestrzeni-ciagow-znakow}

\section{Podstawowe definicje}

CZY TO JAKO CIĄGŁY TEKST CZY WSZYSTKO PISAĆ W DEFINICJI???

\begin{definition}
Niech  $\Sigma = \{\Sigma_i\}$ będzie skończonym uporządkowanym alfabetem o~wielkości $|\Sigma|$.~\emph{Napisem} nazywamy skończony ciąg znaków z~$\Sigma$.~Zbiór wszystkich napisów o~długości $n$~nad $\Sigma$~jest oznaczony przez $\Sigma^n$,~podczas gdy przez $\Sigma^* = \bigcup_{n=1}^{\infty}\Sigma^n$ rozumiemy zbiór wszystkich napisów utworzonych ze~znaków z~$\Sigma$~\cite{Boytsov2011:indexingmethods}.\\

O~ile nie podano inaczej, używamy zmiennych $s,\ t,\ u,\ v,\ w,\ x,\ y$ jako oznaczenie napisów oraz $a,\ b,\ c$ do oznaczenia napisów jednoznakowych albo po~prostu \emph{znaków}. Pusty napis jest oznaczany jako $\varepsilon$. Przez $|s|$, dla każdego napisu $s \in \Sigma^*$, rozumiemy jego długość, czyli liczbę znaków w~napisie. Ciąg zmiennych oznaczających napisy i/lub znaki oznaczają ich złączenie~\cite{Boytsov2011:indexingmethods}.\\

Poprzez $s_i$~rozumiemy $i$-ty znak z~napisu $s$,~dla każdego $i \in \{1,\ldots,|s|\}$. Podciąg kolejnych przylegających do~siebie znaków z~napisu nazywamy \emph{podnapisem}. Podnapisem napisu $s$,~który zaczyna się od~$i$-tego znaku, a~kończy na~$j$-tym znaku, oznaczamy przez $s_{i:j}$, tj. $s_{i:j} = s_is_{i+1}\ldots s_j$ dla $i<j$. Zakładamy również, że~jeśli $j<i$, to $s_{i:j} = \varepsilon$~\cite{Boytsov2011:indexingmethods,Loo2014:stringdist}.\\

Załóżmy, że~napis $s$~jest resprezentacją złączenia trzech, być może pustych, podnapisów $w$, $x$ i $y$, tj. $s = wxy$. Wówczas podnapis $w$ nazywamy \emph{prefiksem}, natomiast podnapis $y$ -- sufiksem~\cite{Boytsov2011:indexingmethods}.\\

Podnapis o ustalonej długości $q$ jest nazywany \emph{$q$-gramem}. $q$-gramy o $q$ równym jeden, dwa lub trzy mają specjalne nazwy: \emph{unigram, bigram} i \emph{trigram}. Jeśli $q > |s|$, to $q$-gramy napisu są naisami pustymi~\cite{Boytsov2011:indexingmethods}.
\end{definition}

%\begin{definition}
%\emph{Napisem} nazywamy skończone złączenie symboli (znaków) ze~skończonego \emph{alfabetu}, oznaczonego przez $\Sigma$. Produkt kartezjański rzędu $q$, $\Sigma\times\ldots\times\Sigma$ oznaczamy przez $\Sigma^q$, natomiast zbiór wszystkich skończonych napisów, które można utworzyć ze~znaków z $\Sigma$ oznaczamy przez~$\Sigma^*$. \emph{Pusty napis}, oznaczany $\varepsilon$, również należy do~$\Sigma^*$. Napisy zwyczajowo będziemy oznaczać przez $s$,~$t$~oraz $u$,~a~ich \emph{długość}, czyli liczbę znaków w~napisie, przez $|s|$. Poprzez $s_i$ rozumiemy $i$-ty znak z napisu $s$, dla każdego $i \in \{1,\ldots,|s|\}$, natomiast podnapisy od znaku $i$-tego do znaku $j$-tego oznaczamy przez $s_{i:j}$. Zakładamy również, że jeśli $j<i$, to $s_{i:j} = \varepsilon$ \cite{Loo2014:stringdist}.
%\end{definition}


\begin{example}
Niech $\Sigma$ będzie alfabetem złożonym z~$26$ małych liter alfabetu łacińskiego oraz niech $s = 'ela'$. Wówczas mamy $|s| = 3$, $s \in \Sigma^3$ oraz $s \in \Sigma$. Co więcej, mamy $s_1 = 'e'$, $s_2 = 'l'$, $s_3 = 'a'$. Podnapis $1:2$ napisu $s$ to $s_{1:2} = 'el'$. W napisie tym mamy do czynienia jedynie z $q$-gramami o $q$ równym jeden, dwa oraz trzy: $'e',\ 'l',\ 'a'$; $'el',\ 'la'$ oraz $'ela'$ odpowiednio.
\end{example}


[TU TRZEBA BARDZIEJ FORMALNIE! BOYTSOV STR. 4-7]Odległość $d(s,t)$ pomiędzy dwoma napisami $s$~i~$t$~to~minimalny koszt ciągu operacji potrzebnego do~przetransformowania $s$~w~$t$ (i~$\infty$, gdy taki ciąg nie istnieje). Koszt ciągu operacji jest sumą kosztów pojedynczych operacji. Przez operacje rozumiemy skończoną liczbę reguł w~formie $\delta(x, y) = a$, gdzie $x$~i~$y$ to różne podnapisy, a~$a$~to~nieujemna liczba rzeczywista. Kiedy już, przy pomocy operacji, podnapis $x$~zostanie przekształcony w~napis $y$,~żadne dalsze operacje nie mogą być wykonywane na~$y$~\cite{Navarro2001:guidedtour}.

Zauważmy w~szczególności ostatnie ograniczenie, które nie pozwala wielokrotnie przekształcać tego samego podnapisu. DO POPRAWKI!!!: Gdyby pominąć to~założenie, każdy system przekształcający napisy spełniałby definicję i~stąd odległość między dwoma napisami nie byłaby, w~ogólności, możliwa do~policzenia~\cite{Navarro2001:guidedtour}.

Jeśli dla każdej operacji $\delta(x,y)$, istnieje odpowiednia operacja $\delta(y,x)$ o~takim samym koszcie, to~odległość jest symetryczna (tj. $d(s,t) = d(t,s)$). Zauważmy również,~że:
\begin{itemize}
\item $d(s,t) \geq 0$ dla wszystkich napisów $s, t$,
\item $d(s,s) = 0$,
\item $d(s,u) \leq d(s,t) + d(t,u)$.
\end{itemize}
Stąd, jeśli odległość jest symetryczna, przestrzeń napisów tworzy przestrzeń metryczną~\cite{Navarro2001:guidedtour}.

\begin{definition}
\label{def:001}
Funkcję $d$ nazywamy \emph{metryką} na~$\Sigma^*$, jeśli ma~poniższe własności:
\begin{enumerate}
\item \label{def:001a} $d(s,t) \geq 0$
\item \label{def:001b} $d(s,t) = 0$ wtedy i tylko wtedy, gdy $s = t$
\item \label{def:001c} $d(s,t) = d(t,s)$
\item \label{def:001d} $d(s,u) \leq d(s,t) + d(t,u)$,
\end{enumerate}
gdzie $s$,~$t$,~$u$~są~napisami z~$\Sigma^*$.


\end{definition}

%Z~powyższej definicji wynika, że~dla dowolnych $s,\ t \in \Sigma^*,\ d(s, t) \geq 0$.


Odległości na napisach można podzielić na~trzy grupy:
\begin{itemize}
\item oparte na~operacjach edycyjnych (\emph{edit operations}),
\item oparte na~$q$-gramach,
\item miary heurystyczne.
\end{itemize}


\section{Odległości na napisach oparte na operacjach edycyjnych}

HISTORIA ODLEGLOSCI EDYCYJNYCH?

Odległość edycyjna $ED(s,t)$ pomiędzy dwoma napisami $s$~i~$t$~to~minimalna liczba operacji edycyjnych potrzebna do~przetworzenia $s$~w~$t$ (i~$\infty$, gdy taki ciąg nie istnieje)~\cite{Navarro2001:guidedtour}. \emph{Ścisłą odległością edycyjną} nazywamy minimalną liczbę nie nakładających się operacji edycyjnych, które pozwalają przekształcić jeden napis w drugi, i które nie przekształcają dwa razy tego samego podnapisu~\cite{Boytsov2011:indexingmethods}.\\

Napis może zostać przetworzony w drugi poprzez ciąg przekształcenia jego podnapisów. Ten ciąg nazywany jest \emph{śladem edycji}, podczas gdy przekształcenia są nazywane \emph{bazowymi} operacjami edycyjnymi. Bazowe operacje edycyjne, które polegają na mapowaniu napisu $s$ w napis $t$, są oznaczane przez $s \rightarrow t$. Zbiór wszystkich bazowych operacji edycyjnych oznaczamy przez $\mathbb{B}$~\cite{Boytsov2011:indexingmethods}.


Bazowe operacje edycyjne są zazwyczaj ograniczone do:
\begin{itemize}
\item usunięcie znaku: $l \rightarrow \varepsilon$, tj. usunięcie litery $'l'$ , np. $'ela' \rightarrow 'ea'$
\item wstawienie znaku: $\varepsilon \rightarrow l$, tj. wstawienie litery $'l'$, np. $'ela' \rightarrow 'elka'$
\item zamiana znaku: $e \rightarrow a$, tj. zamiana litery $'e'$ na $'a'$, np. $'ala' \rightarrow 'ela'$
\item transpozycja: $el \rightarrow le$, tj. przestawienie dwóch przylegających liter $'e'$ i $'l'$, np. $'ela' \rightarrow 'lea'$
\end{itemize}


Koszt wszystkich powyższych operacji zazwyczaj wynosi $1$. Dla wszystkich odległości, które dopuszczają więcej niż jedną operację edycyjną, może być znaczące nadanie wag poszczególnym operacjom, dając na przykład transpozycji mniejszy koszt niż operacji wstawienia znaku. Odległości, dla których takie wagi zostają nadane są zazwyczaj nazywane \emph{uogólnionymi} odległościami~\cite{Boytsov2011:indexingmethods}.

\begin{property}
Zakładamy, że $\mathbb{B}$ spełnia następujące własności~\cite{Boytsov2011:indexingmethods}:
\begin{itemize}
\item jeśli $s \rightarrow t \in \mathbb{B}$, to odwrotna operacja $t \rightarrow s$ również należy do $\mathbb{B}$;
\item $a \rightarrow a \in \mathbb{B}$ (operacja identycznościowa dla jednego znaku należy do $\mathbb{B}$);
\item zbiór $\mathbb{B}$ jest zupełny: dla dwóch dowolnych napisów $s$ i $t$, istnieje ślad edycji, który przekształca $s$ w $t$.
\end{itemize}
\end{property}

Zauważmy, że zbiór $\mathbb{B}$ nie musi być skończony.

Przykładowe odległości: Hamminga, najdłuższego wspólnego podnapisu (\emph{longest common substring}), Levenshteina, optymalnego dopasowania napisów (\emph{optimal string alignment}), Damareu-Levenshteina. 



\begin{definition}
\emph{Odległością Hamminga}~\cite{Hamming1950:errordetecting} na $\Sigma^*$ nazywamy:
$$
d_{hamming}(s, t) = \left\{
\begin{array}{l l}     
    \sum_{i=1}^{|s|}[1 - \delta(s_i, t_i)], & \text{gdy } |s| = |t|,\\
    \infty, & \text{w przeciwnym przypadku},
\end{array}\right.
$$
gdzie 
$$
\delta(s_i, t_i) = \left\{
\begin{array}{l l}     
    1, & \text{gdy } s_i = t_i,\\
    0, & \text{w przeciwnym przypadku}.
\end{array}\right.
$$
\end{definition}

%Odległość Hamminga dopuszcza jedynie zamianę znaku, stąd jest zdefiniowana tylko dla napisów o~równej długości. 
Łatwo zauważyć, że~odległość Hamminga spełnia definicję metryki. Intuicyjnie rzecz biorąc odległość Hamminga zlicza liczbę indeksów, na~których dwa napisy mają różny znak. Odległość ta~przyjmuje wartości ze~zbioru $\{0,\ldots,|s|\}$, gdy $|s|=|t|$, natomiast jest równa nieskończoności, gdy napisy mają różne długości.

[PIĘKNY RYSUNEK??]

\begin{example}
Odległość Hamminga między słowami \emph{koza} i \emph{foka} wynosi $d_{hamming}(koza, foka) = 2$, natomiast między słowami \emph{koza} i \emph{foczka} wynosi ona $d_{hamming}(koza, foczka) = \infty$.
\end{example}

\begin{definition}
\emph{Odległością najdłuższego wspólnego podnapisu}~\cite{Needleman2008:generalmethod} na $\Sigma^*$ nazywamy:
$$
d_{lcs}(s, t) = \left\{
\begin{array}{l l}     
    0, & \text{gdy } s = t = \varepsilon,\\
    d_{lcs}(s_{1:|s|-1}, t_{1:|t|-1}), & \text{gdy } s_{|s|} = t_{|t|}, \\
    1+min\{d_{lcs}(s_{1:|s|-1}, t), d_{lcs}(s, t_{1:|t|-1})\}, & \text{w przeciwnym przypadku},
\end{array}\right.
$$
\end{definition}

Odległość najdłuższego wspólnego podnapisu również spełnia definicję metryki. Przyjmuje wartości ze zbioru $\{0, |s|+|t|\}$, przy czym maksimum jest osiągane, gdy $s$ i $t$ nie mają ani jednego wspólnego znaku.
Odległość ta zlicza liczbę usunięć i~wstawień, potrzebnych do~przetworzenia jednego napisu w~drugi. 

\begin{example}
Odległość najdłuższego wspólnego podnapisu między słowami \emph{koza} i \emph{foka} wynosi: $d_{lsc}('koza', 'foka') = 4$, bo~$koza  \xrightarrow[1]{us.\ k} oza \xrightarrow[1]{us.\ z} oa  \xrightarrow[1]{wst.\ f} foa \xrightarrow[1]{wst.\ k} foka$.
\end{example}

Powyższy przykład pokazuje, że~w~ogólności nie ma~unikalnej najkrótszej drogi transformacji jednego napisu w~drugi, gdyż można zamienić kolejność usuwania (lub wstawiania) znaków i~również uzyskać odlegość równą~$4$.

Jak sugeruje nazwa, odległość najdłuższego wspólnego podnapisu, ma~też inną interpretację. Poprzez wyrażenie \emph{najdłuższy wspólny podnapis} rozumiemy najdłuższy ciąg utworzony przez sparowanie znaków z~$s$~i~$t$~nie zmieniając ich porządku. Wówczas odległość ta~jest rozumiana jako liczba niesparowanych znaków z~obu napisów. W~powyższym przykładzie może to~być zwizualizowane następująco:
	
[PIĘKNY RYSUNEK??]

Jak widać na~rysunku, litery $'k',\ 'z',\ 'f'$ i $'k'$ pozostają bez pary, dając odległość równą~$4$.

\begin{definition}
Uogólnioną \emph{odległością Levenshteina} \cite{Levenshtein1965:binarycodes}~na~$\Sigma^*$~nazywamy:
$$
d_{lv}(s, t) = \left\{
\begin{array}{l l}     
    0, & \text{gdy } s = t = \varepsilon,\\
    min\{ & \\
\qquad    d_{lv}(s, t_{1:|t|-1}) + w_1, & \\
\qquad    d_{lv}(s_{1:|s|-1}, t) + w_2, & \\
\qquad    d_{lv}(s_{1:|s|-1}, t_{1:|t|-1}) + [1-\delta(s_{|s|}, t_{|t|})]w_3 & \\
\qquad    \}, & \text{w przeciwnym przypadku},
\end{array}\right.
$$
gdzie $w_1, w_2$~i~$w_3$~to~niezerowe liczby rzeczywiste, oznaczające kary za~usunięcie, wstawienie oraz zamianę znaku.
\end{definition}

Odległość ta~zlicza ważoną sumę usunięć, wstawień oraz zamian znaków, potrzebnych do~przetworzenia jednego napisu w~drugi. Gdy za~wagi przyjmie się $1$~mamy do~czynienia ze~zwykłą odległością Levenshteina, np.~$d_{lv}('koza', 'foka') = 2$, bo $koza  \xrightarrow[1]{zm.\ k\ na\ f} foza  \xrightarrow[1]{zm.\ z\ na\ k} foka$. Powyższy przykład ilustruje, że dodatkowa elastyczność w~porównaniu do~odległości najdłuższego wspólnego podnapisu, daje mniejszą wartość odległości między napisami, jako że~potrzebujemy jedynie dwóch zamian znaków~\cite{Loo2014:stringdist}.

Gdy za~wagi przyjmiemy np. $(0.1, 1, 0.3)$, to $d_{lv}('koza', 'foka') = 0.6$, bo~$koza  \xrightarrow[0.3]{zm.\ k\ na\ f} foza  \xrightarrow[0.3]{zm.\ z\ na\ k} foka$.

Uogólniona odległość Levenshteina spełnia definicję metryki, gdy $w_1 = w_2$. W przeciwnym przypadku nie spełnia ona założenia o~symetrii, tj.~podpunktu \ref{def:001c}~definicji \ref{def:001}.~Jednakowoż, symetria zostaje zachowana przy jednoczesnej zamianie $s$~i~$t$~oraz $w_1$~i~$w_2$,~jako że~liczba usunięć znaków przy przetwarzaniu napisu $s$~w~napis $t$~jest równa liczbie wstawień znaków przy przetwarzaniu napisu $t$~w~napis $s$~\cite{Loo2014:stringdist}.~Dobrze obrazuje to~następujący przykład.

\begin{example}
Przyjmijmy za~$(w_1, w_2, w_3) = (0.1, 1, 0.3)$. Wówczas uogólniona odległość Levenshteina dla napisów \emph{koza} i~\emph{foczka} wynosi:
\begin{equation}
\label{eq:001}
d_{lv}('koza', 'foczka') = 0.5,
\end{equation}
bo
$$
koza  \xrightarrow[0.3]{zm.\ k\ na\ f} foza  \xrightarrow[0.1]{wst. c} focza \xrightarrow[0.1]{wst. k} foczka,
$$
natomiast
\begin{equation}\label{eq:002}
d_{lv}('foczka', 'koza') = 2.3,
\end{equation}
bo
$$
foczka  \xrightarrow[0.3]{zm.\ f\ na\ k} koczka  \xrightarrow[1]{us. c} kozka \xrightarrow[1]{us. k} koza.
$$
Gdy za~wagi $(w_1, w_2, w_3)$ przyjmiemy $(1, 0.1, 0.3)$, to~uogólniona odległość Levenshteina wynosi:
$$
d_{lv}('koza', 'foczka') = 2.3,
$$
bo
$$
koza  \xrightarrow[0.3]{zm.\ k\ na\ f} foza  \xrightarrow[1]{wst. c} focza \xrightarrow[1]{wst. k} foczka,
$$
czyli analogicznie, jak w~przypadku \ref{eq:002}. Natomiast
$$
d_{lv}('foczka', 'koza') = 0.5,
$$
bo
$$
foczka  \xrightarrow[0.3]{zm.\ f\ na\ k} koczka  \xrightarrow[0.1]{us. c} kozka \xrightarrow[0.1]{us. k} koza,
$$
czyli analogicznie, jak w~przypadku \ref{eq:001}.
\end{example}


\begin{definition}
\emph{Odległością optymalnego dopasowania napisów} na~$\Sigma^*$~nazywamy:
$$
d_{osa}(s, t) = \left\{
\begin{array}{l l}     
    0, & \text{gdy } s = t = \varepsilon,\\
    min\{ & \\
\qquad    d_{osa}(s, t_{1:|t|-1}) + w_1, & \\
\qquad    d_{osa}(s_{1:|s|-1}, t) + w_2, & \\
\qquad    d_{osa}(s_{1:|s|-1}, t_{1:|t|-1}) + [1-\delta(s_{|s|}, t_{|t|})]w_3 & \\
\qquad    d_{osa}(s_{1:|s|-2}, t_{1:|t|-2}) + w_4\text{, gdy } s_{|s|} = t_{|t|-1}, s_{|s|-1} = t_{|t|} & \\
\qquad    \}, & \text{w przeciwnym przypadku},
\end{array}\right.
$$
gdzie $w_1, w_2$, $w_3$~i$w_4$~to~niezerowe liczby rzeczywiste, oznaczające kary za~odpowiednio usunięcie, wstawienie, zamianę oraz transpozycję znaków.
\end{definition}

Odległość optymalnego dopasowania napisów jest bezpośrednim rozszerzeniem odległości Levenshteina, która zlicza również liczbę transpozycji przylegających znaków, potrzebnych do~przetworzenia jednego napisu w~drugi. W~przeciwieństwie do~wcześniej zaprezentowanych odległości, nie spełnia ona nierówności trójkąta, tj. podpunktu \ref{def:001d} z~definicji \ref{def:001} \cite{Loo2014:stringdist}: 
$$2 = d_{osa}('ba', 'ab') + d_{osa}('ab', 'acb') \leq d_{osa}('ba', 'acb') = 3,$$ 
gdyż
$$
ba  \xrightarrow[1]{transp.\ b\ i \ a} ab + ab \xrightarrow[1]{wst. c} acb,
$$
natomiast
$$
ba  \xrightarrow[1]{us.\ b} a \xrightarrow[1]{wst.\ c} ac \xrightarrow[1]{wst.\ b} acb.
$$
W ostatnim przykładzie, zmniejszenie odległości poprzez zamianę liter $'a'$ i $'b'$, a następnie wstwienie litery $'c'$ spowodowałoby dwukrotne przekształcenie tego samego podnapisu. Z tego powodu odległość optymalnego dopasowania napisów bywa również nazywana \emph{ścisłą odległością Damerau-Levenshteina} i jest często mylona z właściwą \emph{odległością Damerau-Levenshteina}. Ta ostatnia pozwala na przekształcanie tego samego podnapisu wielokrotnie i jest metryką w rozumieniu definicjij \ref{def:001}, ale nie spełnia założenia o nie przekształcaniu wielokrotnie tego samego podnapisu \cite{Loo2014:stringdist}.

[MIARA DAMERAU-LEVENSHTEINA??? WTEDY ZMIENIC DEFINICJE O NIEPRZERABIANIU 2 RAZY TEGO SAMEGO PODNAPISU]

W~przypadku odległości Levenshteina i~odległości optymalnego dopasowania napisów, maksymalna odległość między napisami $s$~i~$t$~wynosi $max\{|s|, |t|\}$. Jednakowoż, gdy liczba dopuszczalnych operacji edycyjnych rośnie, to liczba dopuszczalnych ścieżek między napisami wzrasta, co pozwala ewentualnie zmiejszyć odległość między napisami. Dlatego relację między zaprezentowanymi powyżej odległościami można podsumować następująco~\cite{Loo2014:stringdist}:
$$
\left. \begin{array}{r}
\infty \geq |s| \geq d_{hamming}(s,t) \\
|s| + |t| \geq d_{lcs}(s,t) \\
max\{|s|, |t|\} \\
\end{array} \right \}
\geq d_{lv}(s,t) \geq d_{osa}(s,t) \geq 0.
$$

%-----------Koniec części zasadniczej-----------

%\begin{thebibliography}{11}
%\nocite{Hornik2012:sphkmeans}
%\nocite{Wild2002:sphkmeans}
%\nocite{Loo2014:stringdist}
\bibliographystyle{plain}
\bibliography{bibliography}
%\bibitem[1]{M} Arnold W. Miller, \emph{Special Subsets of the Real Line}, The University of Texas, Austin, U.S.A. 1984.
%\bibitem[2]{H2} J.C. Oxtoby, \emph{Measure and Category}, Springer-Verlag, New York Heidelberg Berlin, 1971.
%\bibitem[3]{WW} Winfried Just and Martin Weese, \emph{Discovering Modern Set Theory. I: The Basics.} Graduate Studies in Mathematics vol. 8, American Mathematical Society, Providence, RI, 1996.
%\bibitem[4]{WW2} Winfried Just and Martin Weese, \emph{Discovering Modern Set Theory. II: Set-Theoretic Tools for Every Mathematician.}, Graduate Studies in Mathematics vol. 18, American Mathematical Society, Providence, RI, 1997.
%\end{thebibliography}
%\clearpage
%\pagestyle{empty}
%\noindent Warszawa, dnia ...............
%\vspace{5cm}
%\begin{center}
%\LARGE{Oświadczenie}
%\end{center}
%Oświadczam, że pracę licencjacką pod tytułem: ,,Automatyczna kategoryzacja tematyczna tekstów przy użyciu metryk w przestrzeni ciągów znaków'', której promotorem jest dr hab. Marek Gągolewski, wykonałem/am samodzielnie, co poświadczam własnoręcznym podpisem.
%\vspace{2cm}
%\begin{flushright}
%...........................................
%\end{flushright}

%\makestatement
\end{document}
