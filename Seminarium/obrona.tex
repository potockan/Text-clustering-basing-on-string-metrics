\documentclass[11pt,pdftex,mathserif]{beamer}
% ewentualnie (w trakcie przygotowania prezentacji):
% \documentclass[...,handout]{beamer} % jedna 'frame' == jeden slajd
\usepackage[T1]{polski}        % jeśli po angielsku, to skasuj
\usepackage[polish]{babel}     % jeśli po angielsku, to skasuj
\selectlanguage{polish}        % jeśli po angielsku, to skasuj
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}  % kodowanie polskich znaków CP1250 (windows)
% Alternatywnie - latin2 dla kodowania ISO-8859-2 (raczej nie Windows)
% latex/pdflatex nie wspiera niestety Unicode (np. UTF-8)
\usepackage{amsmath,amssymb}     % więcej symboli matematycznych
\usepackage{graphicx}            % jeśli chcemy wstawiać grafikę
\usepackage{hyperref}            % odnośniki internetowe, zaawansowane ust. PDF
%\hypersetup{pdfstartview={FitW}}
\usepackage{natbib}
\usepackage{examplep}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{cprotect}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{rotating}
\usepackage{array}
\usepackage{rotating}
\usepackage{longtable}
%%%%%%%%%%%% MOJE ULUBIONE USTAWIENIA BEAMERA %%%%%%%%%%%%%
%
\usetheme{Boadilla} % Warsaw to nazwa stylu - zmień na SWOJĄ ulubioną
\usecolortheme{spruce}
\useoutertheme{infolines}
\useinnertheme{circles}
\usefonttheme{structuresmallcapsserif}
%%
\setbeamertemplate{navigation symbols}{} % WYŁĄCZA PASEK NAWIGACJI U DOŁU
\setbeamercovered{invisible} % WPŁYWA NA WYŚWIETLANIE "SPAUZOWANYCH" ELEMENTÓW

%
\setbeamertemplate{theorems}[numbered]
\definecolor{green2}{rgb}{0.3, 0.6 ,0.4}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\title[Kategoryzacja tematyczna tekstów ]{Automatyczna kategoryzacja tematyczna tekstów przy użyciu metryk w przestrzeni ciągów znaków}
\author[N. Potocka]{Natalia Potocka}
%\institute[MiNI PW]{}
\date[25.01.2016]{25.01.2016}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\newtheorem{twierdzenie}{Twierdzenie}
\renewcommand{\proofname}{Dowód}
\newtheorem{lemat}[twierdzenie]{Lemat}
\newtheorem{wniosek}[twierdzenie]{Wniosek}
\newtheorem{stwierdzenie}[twierdzenie]{Stwierdzenie}

\theoremstyle{definition}
\newtheorem*{definicja}{Definicja}
\newtheorem*{oznaczenie}{Oznaczenie}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\xsr}{\overline{X}_n}
\newcommand{\skw}{S_n^2}
\newcommand{\al}{\alpha}
\newcommand*{\om}{\omega}

\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}


\newenvironment{zrodlo}{\emph{Źródło: }}{\par}

\begin{document}   % jedziemy :-)
%%%%%%%%%%%%% SLAJD TYTUŁOWY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty}% wyłącza paski na górze i na dole
\begin{frame}%

   \begin{center}%
%
%
%   %%%%%%%%%%%% NAGLOWEK %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
      \begin{columns}%
         \begin{column}[c]{1.2cm}\centering%
         \includegraphics[height=1.0cm]{logopw.pdf} \\%
         \end{column}

         \begin{column}[c]{7cm}\centering
            {\footnotesize{Politechnika Warszawska}}\\%
            {\footnotesize{Wydział Matematyki i~Nauk Informacyjnych}}%
         \end{column}

         \begin{column}[c]{1.2cm}\centering%
         \includegraphics[height=1.0cm]{logomini.pdf} \\%
         \end{column}%
      \end{columns}

   %%%%%%%% TYTUL %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

      \vspace*{2em}

      \colorbox{green2}{\parbox{10cm}{\color{black}\centering\LARGE{Automatyczna kategoryzacja tematyczna tekstów przy użyciu metryk w~przestrzeni ciągów znaków}}}

      \vspace*{1.5em}%
      {\Large{Natalia Potocka}}\\%
%      {\color{blue}\footnotesize\texttt{M.Gagolewski@mini.pw.edu.pl}}

      %\vspace*{2.5em}%
      {\it\footnotesize Warszawa, 25.01.2016}  % DATA

   \end{center}

\end{frame}



\begin{frame}{Cel pracy}
Celem pracy jest zbadanie wpływu doboru odległości na~przestrzeni napisów na~jakość automatycznej kategoryzacji tematycznej tekstów. \\
%skategoryzowanie tekstów z~polskiej Wikipedii pod względem tematu na~podstawie liczności słów występujących w~tekście. %Można się spodziewać, że~jeśli w~dwóch tekstach występuje dużo podobnych do~siebie słów, to~pochodzą one z~tej samej kategorii tematycznej. \\
\pause
Problemy:
\begin{itemize}
\item duże wymiary danych ($1\ 075\ 568 \times 2\ 806\ 765$),
\item dane bardzo rzadkie (ponad $99{,}99\%$),
\item duża złożoność obliczeniowa i pamięciowa.
\end{itemize}
\pause
Grupujemy słowa przy użyciu \emph{stemmingu} oraz \emph{odległości na przestrzeni ciągów znaków}.
\end{frame}



\begin{frame}{\emph{Stemming}}
\begin{table}[h]
\centering
\caption{Przykładowe skupienia uzyskane przy pomocy \emph{stemmingu}.}
\begin{tabular}{|lllll|}
  \hline
działalność & niemiecki & odkryty & okres & postać \\ 
  \hline
działalność & niemiecki & odkryta & okres & postaci \\ 
  działalności & niemieckiej & odkryte & okresu & postacie \\ 
  działalnością & niemieckiego & odkryty & okresach & postać \\ 
  działalnościach & niemieckich & odkrytych & okresem & postacią \\ 
  działalnościami & niemieckim & odkrytym & okresy & postaciami \\ 
   & niemiecką & odkrytą & okresów & postaciach \\ 
   & niemiecka & odkrytego & okresami & postaciom \\ 
   & niemieccy & odkrytej & okresom & postał \\ 
   & niemieckimi & odkrytymi &  & postała \\ 
   & niemiecku & nieodkrytych &  & postania \\ 
   & niemieckiemu & nieodkryte &  & postało \\ 
   & nieniemieckich & odkrytemu &  & postały \\ 
   & nieniemieckiej & odkryci &  & postaniu \\ 
   \hline
\end{tabular}
\end{table}

\end{frame}

\begin{frame}
\begin{block}{Definicja}
\emph{Odległością Levenshteina}~\cite{Levenshtein1965:binarycodes} nazywamy:
$$
d_{lv}(s, t) = \left\{
\begin{array}{l l}     
    0, & \text{gdy } s~= t~= \varepsilon,\\
    min\{ & \\
\qquad    d_{lv}(s, t_{1:|t|-1}), & \\
\qquad    d_{lv}(s_{1:|s|-1}, t), & \\
\qquad    d_{\mathrm{lv}}(s_{1:|s|-1}, t_{1:|t|-1}) +\\  
\qquad\qquad\qquad\qquad     \delta(s_{|s|}, t_{|t|}) & \\
\qquad    \}, & \text{w przeciwnym przypadku},
\end{array}\right.
$$
gdzie $s, t$ to napisy, a $\delta(s_{i}, t_{j}) = 0$, gdy $s_i = t_j$ i 1~w~przeciwnym przypadku. 
\end{block}
\end{frame}

%\begin{frame}{Operacje edytowania}
%Odegłości oparte na operacjach edytowania zliczają liczbę opercji potrzebnych do~przetworzenia jednego napisu w~drugi. Najczęściej wymieniamymi operacjami~są~\cite{Boytsov2011:indexingmethods}:
%\begin{itemize}
%\item zamiana znaku, np. $'ela' \rightarrow 'ala'$
%\item usunięcie znaku, np. $'ela' \rightarrow 'ea'$
%\item wstawienie znaku, np. $'ela' \rightarrow 'elka'$
%\item transpozycja dwóch przylegających znaków, np. $'ela' \rightarrow 'lea'$
%\end{itemize}
%\pause
%Przykładowe odległości: Hamminga, najdłuższego wspólnego podnapisu (\emph{longest common substring}), Levenshteina, optymalnego dopasowania napisów (\emph{optimal string alignment}), Damerau-Levenshteina.
%
%\end{frame}
%
%\begin{frame}{Odległości oparte na $q$-gramach}
%\begin{block}{Definicja}
%Podnapis złożony z~kolejnych, przylegających do~siebie znaków, o~ustalonej długości $q\geq 1$ jest nazywany \emph{$q$-gramem}.
%\end{block}
%
%\begin{block}{Definicja}
%Niech $\mathcal{Q}(s,q)$ oznacza zbiór unikalnych $q$-gramów występujących w~napisie $s$. Wówczas \emph{odległość Jaccarda}, $d_{\mathrm{jac}}$, między napisami $s$ i~$t$ definiuje się jako:
%\begin{equation*}
%d_{\mathrm{jac}}(s,t,q) = 1 - \frac{|\mathcal{Q}(s,q) \cap \mathcal{Q}(t,q)|}{|\mathcal{Q}(s,q) \cup \mathcal{Q}(t,q)|},
%\end{equation*}
%gdzie $|\cdot|$ oznacza liczność zbioru.
%\end{block} 
%\end{frame}


%\begin{frame}{Metryki oparte na $q$-gramach}
%\begin{block}{Definicja}
%Niech $s = s_1 s_2 \ldots s_n$ będzie i~niech $x$ będzie $q$-gramem o długości $q$. Jeśli $s_i s_{i+1} \ldots s_{i+q-1} = x$ dla pewnego $i$, to~$x$ \emph{wystąpiło} w~$s$. Niech $\mathbf{v}(s,q)$ będzie wektorem o~długości $|\Sigma|^q$, którego zmienne oznaczają liczbę wystąpień wszystkich możliwych $q$-gramów z~$\Sigma^q$ w~$s$. Niech $s, t~\in \Sigma^*$ oraz $q>0$ będzie liczbą naturalną. \emph{Odległość $q$-gramową} między napisami $s$ i~$t$ definiuje się następująco %~\cite{Ukkonen1992:approxqgrams}:
%\begin{equation*}
%\label{eq:009}
%d_{\mathtt{q}\mathrm{gram}}(s,t,q) = \norm{\mathbf{v}(s,q) - \mathbf{v}(t,q)}_1 = \sum\limits_{i = 1}^{|\Sigma|^q} |v_i(s,q) - v_i(t,q)|.
%\end{equation*}
%\end{block} 
%\end{frame}

%\begin{frame}{Miary heurystyczne}
%Niech $s$~i~$t$ będą napisami. Niech $m$ oznacza liczbę wspólnych znaków z~$s$~i~$t$, przy czym zakładając, że~$s_i = t_j$, to~znak ten jest \emph{wspólny} dla obu napisów, jeśli $ |i -j| < \lfloor\frac{max\{|s|, |t|\}}{2}\rfloor$
%i każdy znak z~$s$ może być wspólny ze~znakiem z~$t$ tylko raz. W~końcu, jeśli $s^\prime$ i~$t^\prime$ są~podnapisami utworzonymi z~$s$ i~$t$ poprzez usunięcie znaków, które nie są~wspólne dla obu napisów, to~$T$ jest liczbą transpozycji potrzebnych to~otrzymania $t^\prime$ z~$s^\prime$. Transpozycje znaków nieprzylegających są~dozwolone.
%\begin{block}{Definicja}
%\emph{Odległość Jaro} definiuje się jako~\cite{Loo2014:stringdist}:
%\begin{equation*}
%\label{eq:011}
%d_{\mathrm{jaro}}(s,t) = \left\{
%\begin{array}{l l}     
%    0, & \text{gdy } s~= t~= \varepsilon, \\
%    1, & \text{gdy } m~= 0 \text{ i~} |s| + |t| > 0, \\
%    1 - \frac{1}{3} (\frac{m}{|s|} + \frac{m}{|t|} + \frac{m - T}{m}) & \text{w przeciwnym przypadku}.
%\end{array}\right.
%\end{equation*}
%\end{block}
%\end{frame}

\begin{frame}{Utworzenie skupień słów}
Zaproponowano trzy algorytmy opierające się na wybranych odległościach:
\begin{enumerate}
\item\label{p:001} dołączenie do~skupień słów jeszcze niepogrupowanych,
\item\label{p:002} dołączenie do~skupień zawierających pięć i~więcej elementów, podzbiorów o~mniejszej liczności,
\item zastosowanie najpierw punktu~\ref{p:001}, a~następnie punktu~\ref{p:002}.
\end{enumerate}
\pause
W ten sposób otrzymano 16 różnych reprezentacji tekstów.
\end{frame}



\begin{frame}{Algorytm $k$-średnich}
\begin{block}{Algorytm $k$-średnich}
W~metodzie $k$-średnich minimalizujemy
$$
\sum_i d(\mathbf{x}_i, \mathbf{m}_{C(i)}),
$$
gdzie $\mathbf{x}_i$ to~wektor cech, $C(i) \in \{1,\ldots,k\}$ to~identyfikator skupienia, $\mathbf{m}_1,\ldots,\mathbf{m}_k$ to~środek skupienia ($\mathbf{m}_l = \frac{1}{n_l} \sum\limits_{C(i) = l} \mathbf{x}_i$, gdzie $n_l$~to~liczność $l$-tego skupienia), a~$d$~to~odległość Euklidesowa.
\end{block}
\pause
W metodach najszybszego spadku~\cite{Bottou1995:convergenceproperties}
\begin{align}
%n^{(t+1)}_l& = n^{(t)}_l + \left\{
%\begin{array}{l l}     
%    1, & \text{gdy } l~= C(i), \\
%    0, & \text{wpp.}
%\end{array}\right. \\
\mathbf{m}_l^{(t+1)}& = \mathbf{m}_l^{(t)} + \left\{
\begin{array}{l l}     
    \frac{1}{n_l}(\mathbf{x}_i - \mathbf{m}^{(t)}_l), & \text{gdy } l~= C(i), \\
    0, & \text{wpp.}
\end{array}\right.
\end{align}
\end{frame}


\begin{frame}{Wnioski}
\begin{itemize}
\item Użycie odległości na przestrzeni ciągów znaków ma pozytywny wpływ na kategoryzację tematyczną tekstów.
\item Dla dwóch odległości zaobserwowano lepsze wyniki niż w przypadku pozostałych.
\item Najlepsze rezultaty zostały otrzymane przy użyciu algorytmu 3.
\end{itemize}
\end{frame}

\begin{frame}{Bibliografia}
%\nocite{Hornik2012:sphkmeans}
%\nocite{Wild2002:sphkmeans}
%\nocite{Loo2014:stringdist}
\bibliographystyle{plain}
\bibliography{bibliography}
\end{frame}





\end{document}
