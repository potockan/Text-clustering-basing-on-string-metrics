\documentclass[11pt,pdftex,mathserif]{beamer}
% ewentualnie (w trakcie przygotowania prezentacji):
% \documentclass[...,handout]{beamer} % jedna 'frame' == jeden slajd
\usepackage[T1]{polski}        % jeśli po angielsku, to skasuj
\usepackage[polish]{babel}     % jeśli po angielsku, to skasuj
\selectlanguage{polish}        % jeśli po angielsku, to skasuj
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}  % kodowanie polskich znaków CP1250 (windows)
% Alternatywnie - latin2 dla kodowania ISO-8859-2 (raczej nie Windows)
% latex/pdflatex nie wspiera niestety Unicode (np. UTF-8)
\usepackage{amsmath,amssymb}     % więcej symboli matematycznych
\usepackage{graphicx}            % jeśli chcemy wstawiać grafikę
\usepackage{hyperref}            % odnośniki internetowe, zaawansowane ust. PDF
%\hypersetup{pdfstartview={FitW}}
\usepackage{natbib}
%%%%%%%%%%%% MOJE ULUBIONE USTAWIENIA BEAMERA %%%%%%%%%%%%%
%
\usetheme{Boadilla} % Warsaw to nazwa stylu - zmień na SWOJĄ ulubioną
\usecolortheme{spruce}
\useoutertheme{infolines}
\useinnertheme{circles}
\usefonttheme{structuresmallcapsserif}
%%
\setbeamertemplate{navigation symbols}{} % WYŁĄCZA PASEK NAWIGACJI U DOŁU
\setbeamercovered{invisible} % WPŁYWA NA WYŚWIETLANIE "SPAUZOWANYCH" ELEMENTÓW

%
\setbeamertemplate{theorems}[numbered]
\definecolor{green2}{rgb}{0.3, 0.6 ,0.4}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\title[Kategoryzacja tematyczna tekstów ]{Automatyczna kategoryzacja tematyczna tekstów przy użyciu metryk w przestrzeni ciągów znaków}
\author[N. Potocka]{Natalia Potocka}
%\institute[MiNI PW]{}
\date[21.04.2015]{21.04.2015}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\newtheorem{twierdzenie}{Twierdzenie}
\renewcommand{\proofname}{Dowód}
\newtheorem{lemat}[twierdzenie]{Lemat}
\newtheorem{wniosek}[twierdzenie]{Wniosek}
\newtheorem{stwierdzenie}[twierdzenie]{Stwierdzenie}

\theoremstyle{definition}
\newtheorem*{definicja}{Definicja}
\newtheorem*{oznaczenie}{Oznaczenie}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\xsr}{\overline{X}_n}
\newcommand{\skw}{S_n^2}
\newcommand{\al}{\alpha}
\newcommand*{\om}{\omega}


\newenvironment{zrodlo}{\emph{Źródło: }}{\par}

\begin{document}   % jedziemy :-)
%%%%%%%%%%%%% SLAJD TYTUŁOWY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty}% wyłącza paski na górze i na dole
\begin{frame}%

   \begin{center}%
%
%
%   %%%%%%%%%%%% NAGLOWEK %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
      \begin{columns}%
         \begin{column}[c]{1.2cm}\centering%
         \includegraphics[height=1.0cm]{logopw.pdf} \\%
         \end{column}

         \begin{column}[c]{7cm}\centering
            {\footnotesize{Politechnika Warszawska}}\\%
            {\footnotesize{Wydział Matematyki i~Nauk Informacyjnych}}%
         \end{column}

         \begin{column}[c]{1.2cm}\centering%
         \includegraphics[height=1.0cm]{logomini.pdf} \\%
         \end{column}%
      \end{columns}

   %%%%%%%% TYTUL %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

      \vspace*{2em}

      \colorbox{green2}{\parbox{10cm}{\color{black}\centering\LARGE{Automatyczna kategoryzacja tematyczna tekstów przy użyciu metryk w~przestrzeni ciągów znaków}}}

      \vspace*{1.5em}%
      {\Large{Natalia Potocka}}\\%
%      {\color{blue}\footnotesize\texttt{M.Gagolewski@mini.pw.edu.pl}}

      %\vspace*{2.5em}%
      {\it\footnotesize Warszawa, 25.01.2016}  % DATA

   \end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%CZESC NATALII%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Cel pracy}
Celem pracy jest skategoryzowanie tekstów z~polskiej Wikipedii pod względem tematu na~podstawie liczności słów występujących w~tekście. %Można się spodziewać, że~jeśli w~dwóch tekstach występuje dużo podobnych do~siebie słów, to~pochodzą one z~tej samej kategorii tematycznej. \\
\pause
Problemy:
\begin{itemize}
\item duże wymiary danych (1 075 568 $\times$ 2 806 765),
\item dane bardzo rzadkie (ponad $99{,}99\%$),
\item duża złożoność obliczeniowa i pamięciowa.
\end{itemize}
\pause
Remedium to redukcja liczba słów przy użyciu \emph{stemmingu} oraz \emph{odległości na przetrzeni ciągów znaków}.
\end{frame}



\begin{frame}{\emph{Stemming}}
\begin{table}[h]
\centering
\caption{Przykładowe skupienia uzyskane przy pomocy \emph{stemmingu}.}
\begin{tabular}{|lllll|}
  \hline
działalność & niemiecki & odkryty & okres & postać \\ 
  \hline
działalność & niemiecki & odkryta & okres & postaci \\ 
  działalności & niemieckiej & odkryte & okresu & postacie \\ 
  działalnością & niemieckiego & odkryty & okresach & postać \\ 
  działalnościach & niemieckich & odkrytych & okresem & postacią \\ 
  działalnościami & niemieckim & odkrytym & okresy & postaciami \\ 
   & niemiecką & odkrytą & okresów & postaciach \\ 
   & niemiecka & odkrytego & okresami & postaciom \\ 
   & niemieccy & odkrytej & okresom & postał \\ 
   & niemieckimi & odkrytymi &  & postała \\ 
   & niemiecku & nieodkrytych &  & postania \\ 
   & niemieckiemu & nieodkryte &  & postało \\ 
   & nieniemieckich & odkrytemu &  & postały \\ 
   & nieniemieckiej & odkryci &  & postaniu \\ 
   \hline
\end{tabular}
\end{table}

\end{frame}



\begin{frame}{Operacje edytowania}
Odegłości oparte na operacjach edytowania zliczają liczbę opercji potrzebnych do~przetworzenia jednego napisu w~drugi. Najczęściej wymieniamymi operacjami~są~\cite{Boytsov2011:indexingmethods}:
\begin{itemize}
\item zamiana znaku, np. $'ela' \rightarrow 'ala'$
\item usunięcie znaku, np. $'ela' \rightarrow 'ea'$
\item wstawienie znaku, np. $'ela' \rightarrow 'elka'$
\item transpozycja dwóch przylegających znaków, np. $'ela' \rightarrow 'lea'$
\end{itemize}
\pause
Przykładowe odległości: Hamminga, najdłuższego wspólnego podnapisu (\emph{longest common substring}), Levenshteina, optymalnego dopasowania napisów (\emph{optimal string alignment}), Damerau-Levenshteina.

\end{frame}

\begin{frame}{Metryki oparte na $q$-gramach}
\begin{block}{Definicja}
Podnapis złożony z~kolejnych, przylegających do~siebie znaków, o~ustalonej długości $q\geq 1$ jest nazywany \emph{$q$-gramem}.
\end{block}
\end{frame}



\begin{frame}{Metryki oparte na operacjach edytowania}

\end{frame}

\begin{frame}{Postępy prac}

\end{frame}



\begin{frame}{Postępy prac}
\begin{figure}[h]
      \centering
      \includegraphics[width=12cm] {lv}
      \caption{Przykładowe klastry utworzone przy pomocy metryki Levenshteina. Maksymalna odległość w~klastrze to~$7$.}
    \end{figure}
\end{frame}



\begin{frame}{Postępy prac}
\begin{figure}[h]
      \centering
      \includegraphics[width=12cm] {lcs}
      \caption{Przykładowe klastry utworzone przy pomocy metryki $lcs$. Maksymalna odległość w~klastrze to~$7$.}
    \end{figure}
\end{frame}



\begin{frame}{Postępy prac}
\begin{figure}[h]
      \centering
      \includegraphics[width=12cm] {osa}
      \caption{Przykładowe klastry utworzone przy pomocy metryki $osa$. Maksymalna odległość w~klastrze to~$7$.}
    \end{figure}
\end{frame}



\begin{frame}{Postępy prac}
Z~powodu słabej jakości klastrowania oraz braku możliwości obliczeniowych dokonano klastrowania przy pomocy tzw. \emph{stemmingu}. Polega on~na~przyporządkowaniu do~słowa jego rdzenia, a~więc takiej jego części, która jest odporna na odmiany przez rodzaje, przyimki, przypadki itd.\\
Przykładowo dla słowa \emph{używająca} rdzeniem jest \emph{żyw}.\\
\pause
Do~stemmingu użyto narzędzia Hunspell, które sprawdza pisownię dla wielu programów, takich jak:  OpenOffice, Mozilla Firefox, Thunderbird czy Google Chrome.\\
Dzięki niemu udało się poklastrować $733\ 828$ słów ($\approx 26\%$ wszystkich) z~czego $89\%$ stanowiły polskie słowa $5,5\%$ - słowa angielskie, a~po~ponad $2\%$ - słowa francuskie i niemieckie. Innych języków nie sprawdzano. Liczba uzyskanów klastrów to~$186\ 942$.\\
\pause
Co z pozostałymi słowami?\\
Słowa, które wystąpiły więcej niż raz we~wszystkich tekstach, dołączono do~już istniejących klastrów przy pomocy metryk. Takich słów było $973\ 855$, co~dało łącznie poklastrowanych słów w~liczbie $1\ 707\ 683$.
\end{frame}


\begin{frame}{Postępy prac}
\begin{figure}[h]
      \centering
      \includegraphics[width=12cm] {clust_all2}
      \caption{Przykładowe klastry utworzone przy pomocy Hunspella oraz metryki $lcs$.}
    \end{figure}
\end{frame}


\begin{frame}{Postępy prac}
Następnie dla próbki tekstów z~trzech kategorii: matematyka, historia sztuki oraz wojny, dokonano klasteryzacji artykułów. Kryterium była liczność \textbf{grup słów} występujących w~danym tekście. Do klastrowania użyto metody \emph{sferycznych $k$-średnich}.\\
\pause
\begin{block}{Przypomnienie}
W~metodzie $k$-średnich minimalizujemy
$$
\sum_i d(x_i, p_{c(i)}),
$$
gdzie $x_i$ to~zbiór wektorów cech, $c(i) \in \{1,\ldots,k\}$ to~indentyfikator klastra, $p_1,\ldots,p_k$ to~środek klastra, a~$d$~to~odległość euklidesowa.
\end{block}
\end{frame}

\begin{frame}{Postępy prac}
W~metodzie $k$-średnich minimalizujemy
$$
\sum_i d(x_i, p_{c(i)}),
$$
gdzie $x_i$ to~zbiór wektorów cech, $c(i) \in \{1,\ldots,k\}$ to~indentyfikator klastra, $p_1,\ldots,p_k$ to~środek klastra, a~$d$~to~odległość euklidesowa.
\begin{block}{Metoda sferyczna}
W~metodzie sferycznych $k$-średnich minimalizujemy \cite{Hornik2012:sphkmeans, Wild2002:sphkmeans}
$$
\sum_i d(x_i, p_{c(i)}) = \sum_i 1-\cos(x_i, p_{c(i)}) = \sum_i 1-\frac{<x_i, p_{c(i)}>}{||x_i||\cdot ||p_{c(i)}||},
$$
\end{block}
\end{frame}

% 
% \begin{frame}{Postępy prac}
% W metodzie $k$-średnich minimalizujemy
% $$
% \sum_i d(x_i, p_{c(i)}),
% $$
% gdzie $x_i$ to zbiór wektorów cech, $c(i) \in \{1,\ldots,k\}$ to indentyfikator klastra, $p_1,\ldots,p_k$ to środek klastra, a $d$ to odległość euklidesowa.
% \begin{block}{Metoda sferyczna}
% W metodzie sferycznych $k$-średnich minimalizujemy
% $$
% \sum_i d(x_i, p_{c(i)}) = \sum_i 1-\cos(x_i, p_{c(i)}) = \sum_i 1-\frac{<x_i, p_{c(i)}>}{||x_i||\cdot ||p_{c(i)}||},
% $$
% \end{block}
% \end{frame}


\begin{frame}{Postępy prac}
Opierając się na~kategoriach z~Wikipedii, poprawnie sklasyfikowanych zostało $61\%$ z $59\ 403$ artykułów.
\begin{tabular}{|l|l|r|r|}
  \hline
tytuł & kat & id\_kat & kl \\ 
  \hline
kościół św. rocha w poznaniu & szt & 1 & 1 \\ 
  portret & szt & 1 & 2 \\ 
  quantum of solace (gra komputerowa) & szt & 1 & 2 \\ 
  kurka wodna (seria gier) & szt & 1 & 2 \\ 
  technika macierzy rzadkich & mat & 2 & 2 \\ 
  kryterium walda & mat & 2 & 2 \\ 
  generalized markup language & mat & 2 & 2 \\ 
  czesław falkiewicz & woj & 3 & 3 \\ 
  william goodenough & woj & 3 & 3 \\ 
  kazimierz gallas & woj & 3 & 3 \\ 
  wacław krzywiec & woj & 3 & 3 \\ 
  fabian aleksandrowicz & woj & 3 & 3 \\ 
   \hline
\end{tabular}

% 
% <<echo=FALSE>>=
% library(xtable)
% outcome2 <- readRDS("/home/natalia/Text-clustering-basing-on-string-metrics/Seminarium/art_clust_res2.rds")
% rzedy <- sample(1:nrow(outcome2), 12)
% tab <- outcome2[rzedy, c('title', 'kat_id','kat_id2', 'cluster')]
% tab <- tab[order(tab$kat_id2),]
% names(tab) <- c("tytuł", "kat", "id_kat", "kl")
% tab_out <- xtable(tab)
% digits(tab_out) <- 0
% align(tab_out) <- "|r|l|l|r|r|"
% print((tab_out),include.rownames=FALSE,floating=FALSE)
% @
% 
\end{frame}


\begin{frame}{Co dalej?}
\begin{itemize}
\item znaleźć metodę odpowiednią do~poklastrowania wszystkich artykułów (SGD?), której jakość byłaby zadowalająca
\item rozmyć klastrowanie
\item napisać pracę :)
\end{itemize}
\end{frame}

\begin{frame}{Bibliografia}
%\nocite{Hornik2012:sphkmeans}
%\nocite{Wild2002:sphkmeans}
%\nocite{Loo2014:stringdist}
\bibliographystyle{plain}
\bibliography{bibliography}
\end{frame}


% \begin{frame}{Bibliografia}
% 
% \begin{thebibliography}{}
% \bibitem[1]{AS} Ananda Sen, \textit{On the Interrelation Between the Sample Mean and Sample Variance}, The American Statistician, 66 (2012), 112-117.
% %\bibitem[2]{CZ} L. N. de Castro, F. J. Von Zuben, "\href{http://www.dca.fee.unicamp.br/~vonzuben/research/lnunes_dout/artigos/gecco00.pdf}{\textit{The Clonal Selection Algorithm with Engineering Applications}}", GECCO 2000, Workshop on
% %        Artificial Immune Systems and Their Applications, Las Vegas, USA, str.
% %        36-37, 2000.
% %\bibitem[3]{M} \href{http://mst.mimuw.edu.pl/lecture.php?lecture=mbm&part=Ch12}{http://mst.mimuw.edu.pl/lecture.php?lecture=mbm&part=Ch12}
% %\bibitem[4]{IPIPAN} \href{www.ipipan.waw.pl/\~{}stw/ais/daaisy.html}{www.ipipan.waw.pl/\~{}stw/ais/daaisy.html}
% 
% 
% 
% \end{thebibliography}
% \end{frame}

\begin{frame}{}
   \begin{center}
      \Huge{Dziękuję za uwagę.}
   \end{center}
\end{frame}



\end{document}
